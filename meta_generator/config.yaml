api:
  type: "openai"
  model: "gpt-3.5-turbo"
  params:
    temperature: 0.7
    max_tokens: 1000  # Increased from 100 to 1000 to allow for complete responses
prompt_path: "prompt.md"